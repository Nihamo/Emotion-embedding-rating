{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1-J5RqPBsBg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, LSTM, Flatten, Dense, BatchNormalization, Dropout, LeakyReLU\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "# Loading Data\n",
        "train_data = pd.read_csv(\"/content/train.csv\")\n",
        "\n",
        "# Handling the Missing Values\n",
        "train_data.fillna(train_data.mean(), inplace=True)\n",
        "\n",
        "target_column = \"score\"\n",
        "if target_column not in train_data.columns:\n",
        "    raise KeyError(f\"Target column '{target_column}' not found. Available columns: {train_data.columns}\")\n",
        "\n",
        "# Features and Target\n",
        "X = train_data.drop(columns=[\"ID\", target_column])\n",
        "y = train_data[target_column]\n",
        "\n",
        "# Train-Val Split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize Features using MinMaxScaler (avoids NaN issues)\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "# Reshape for CNN + LSTM\n",
        "X_train_cnn = X_train_scaled.reshape(-1, X_train.shape[1], 1)\n",
        "X_val_cnn = X_val_scaled.reshape(-1, X_train.shape[1], 1)\n",
        "\n",
        "# Optimized CNN + LSTM Model\n",
        "cnn_lstm_model = Sequential([\n",
        "    Conv1D(128, 3, input_shape=(X_train.shape[1], 1)),  # More filters\n",
        "    LeakyReLU(alpha=0.1),  # Prevents dead neurons\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),  # Increased dropout\n",
        "\n",
        "    LSTM(128, return_sequences=True),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(128),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Optimized Adam Optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0003, clipnorm=0.5)\n",
        "cnn_lstm_model.compile(optimizer=optimizer, loss=\"mse\")\n",
        "\n",
        "# Reduce LR on Plateau (prevents overfitting)\n",
        "lr_reducer = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=5, min_lr=1e-5)\n",
        "\n",
        "# Train CNN + LSTM\n",
        "cnn_lstm_model.fit(X_train_cnn, y_train, validation_data=(X_val_cnn, y_val),\n",
        "                   epochs=70, batch_size=32, verbose=1, callbacks=[lr_reducer])\n",
        "\n",
        "# Predict from CNN + LSTM\n",
        "cnn_lstm_preds_train = cnn_lstm_model.predict(X_train_cnn).flatten()\n",
        "cnn_lstm_preds_val = cnn_lstm_model.predict(X_val_cnn).flatten()\n",
        "\n",
        "#  Improved XGBoost Model\n",
        "xgb_model = xgb.XGBRegressor(\n",
        "    n_estimators=2000,  # More trees\n",
        "    learning_rate=0.01,  # Reduced LR\n",
        "    max_depth=10,  # Deeper trees\n",
        "    min_child_weight=2,\n",
        "    colsample_bytree=0.9,\n",
        "    subsample=0.95,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train XGBoost\n",
        "xgb_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict from XGBoost\n",
        "xgb_preds_train = xgb_model.predict(X_train_scaled)\n",
        "xgb_preds_val = xgb_model.predict(X_val_scaled)\n",
        "\n",
        "# *Stacking Model (Ridge Regression for better stability)*\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "stacked_train = np.column_stack((cnn_lstm_preds_train, xgb_preds_train))\n",
        "stacked_val = np.column_stack((cnn_lstm_preds_val, xgb_preds_val))\n",
        "\n",
        "meta_model = Ridge(alpha=0.01)  # L2 Regularization\n",
        "meta_model.fit(stacked_train, y_train)\n",
        "\n",
        "#  Final Prediction\n",
        "final_preds = meta_model.predict(stacked_val)\n",
        "\n",
        "#  Evaluation Metrics\n",
        "mse = mean_squared_error(y_val, final_preds)\n",
        "accuracy = np.mean(np.round(final_preds) == np.round(y_val))  # Exact match percentage\n",
        "\n",
        "#  Harmonic Score Formula\n",
        "hs = (6 * (1/mse) * accuracy) / ((1/mse) + accuracy)\n",
        "\n",
        "print(f\"MSE: {mse:.4f}, Accuracy: {accuracy:.4f}, Harmonic Score: {hs:.4f}\")\n",
        "\n",
        "#  Loading the Test Data\n",
        "test_data = pd.read_csv(\"/content/test.csv\")\n",
        "test_data.fillna(test_data.mean(), inplace=True)\n",
        "\n",
        "# Preparing Test Features\n",
        "test_ids = test_data[\"ID\"]\n",
        "X_test = test_data.drop(columns=[\"ID\"])\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_test_cnn = X_test_scaled.reshape(-1, X_test.shape[1], 1)\n",
        "\n",
        "# Predict using CNN + LSTM and XGBoost\n",
        "cnn_lstm_preds_test = cnn_lstm_model.predict(X_test_cnn).flatten()\n",
        "xgb_preds_test = xgb_model.predict(X_test_scaled)\n",
        "\n",
        "# Stacked Predictions for Test Set\n",
        "stacked_test = np.column_stack((cnn_lstm_preds_test, xgb_preds_test))\n",
        "\n",
        "# Meta-Model Final Prediction\n",
        "final_test_preds = meta_model.predict(stacked_test)\n",
        "\n",
        "# Create Submission File\n",
        "submission = pd.DataFrame({\"ID\": test_ids, \"score\": final_test_preds})\n",
        "submission.to_csv(\"submission_tuned.csv\", index=False)\n",
        "\n",
        "print(\"Submission file saved as submission_tuned.csv \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ypTBWFqBsBl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the submission file\n",
        "submission = pd.read_csv(\"submission_tuned.csv\")\n",
        "\n",
        "# Round the 'score' column to the nearest integer\n",
        "submission[\"score\"] = submission[\"score\"].round().astype(int)\n",
        "\n",
        "# Save it back to the same file\n",
        "submission.to_csv(\"submission_tuned1.csv\", index=False)\n",
        "\n",
        "print(\"Rounded scores (integers) updated in submission.csv successfully!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}